# Tiny LLM

Features:

- Pre-layer normalization
- Nucleus sampling

TODOs:

- KV caching
- SwiGLU activation
- Rotary position embeddings
- Flash attention
